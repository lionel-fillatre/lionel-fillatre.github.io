@article{do_security_2017,
	title = {Security of {SCADA} systems against cyber–physical attacks},
	volume = {32},
	issn = {1557-959X},
	url = {https://ieeexplore.ieee.org/abstract/document/7954148},
	doi = {10.1109/MAES.2017.160047},
	abstract = {Supervisory control and data acquisition (SCADA) systems are highly distributed systems used to control and monitor geographically dispersed assets-often scattered over thousands of square kilometers-in which centralized data acquisition is critical to system operation [1]. These large-scale industrial control systems (ICSs) have been playing an extremely important role in most safety-critical infrastructures [2], such as electric power grids, transportation systems, communication networks, oil and gas pipelines, water distribution and irrigation networks, and multiple facilities including heating, ventilation and air conditioning systems for buildings, and traffic control systems for airports-the list is long. These safety-critical assets, however, are becoming increasingly susceptible to cyber-physical attacks1 on both physical and cyber layers [3].},
	number = {5},
	urldate = {2025-04-25},
	journal = {IEEE Aerospace and Electronic Systems Magazine},
	author = {Do, Van Long and Fillatre, Lionel and Nikiforov, Igor and Willett, Peter},
	month = may,
	year = {2017},
	keywords = {Communication networks, Computer security, Data acquisition, Distributed databases, Power systems, SCADA systems, Servers},
	pages = {28--45},
	file = {Snapshot:/Users/fillatre/Zotero/storage/8G5U2T7P/7954148.html:text/html},
}

@inproceedings{schall_optimal_2025,
	title = {Optimal {One}-hot {Logistic} {Regression} for {Tree}-based {Distribution} {Classification}},
	url = {https://ieeexplore.ieee.org/document/10889704},
	doi = {10.1109/ICASSP49660.2025.10889704},
	abstract = {The importance of features interactions for classification tasks between two classes is proven by the abundance of high-performance machine learning methods using them. In this paper, we take our inspiration from Bayesian Networks (BNs), a famous classification method whose main asset is the graphical representation of links between features. In the case of discrete feature, we assume that the features follow a tree-based distribution under each class. Then, we show that the optimal Bayes classifier coincides with a logistic regression whose features are one-hot encoded with a specific scheme. We show the advantages of such an approach both theoretically and numerically, especially showing that the learning step always converges toward a unique solution. Simulated experiments confirm the efficiency of the one-hot logistic regression with feature interaction encoding.},
	urldate = {2025-04-25},
	booktitle = {{ICASSP} 2025 - 2025 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Schall, Baptiste and Anty, Rodolphe and Fillatre, Lionel},
	month = apr,
	year = {2025},
	note = {ISSN: 2379-190X},
	keywords = {Acoustics, Bayes Classifier, Bayesian Network, Binary classification, Encoding, Light rail systems, Logistic regression, Logistic Regression, Naive Bayes methods, One-hot encoding, Random forests, Signal processing, Speech processing},
	pages = {1--5},
}

@article{gilet_discrete_2022,
	title = {Discrete {Box}-{Constrained} {Minimax} {Classifier} for {Uncertain} and {Imbalanced} {Class} {Proportions}},
	volume = {44},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/document/9302706},
	doi = {10.1109/TPAMI.2020.3046439},
	abstract = {This paper aims to build a supervised classifier for dealing with imbalanced datasets, uncertain class proportions, dependencies between features, the presence of both numeric and categorical features, and arbitrary loss functions. The Bayes classifier suffers when prior probability shifts occur between the training and testing sets. A solution is to look for an equalizer decision rule whose class-conditional risks are equal. Such a classifier corresponds to a minimax classifier when it maximizes the Bayes risk. We develop a novel box-constrained minimax classifier which takes into account some constraints on the priors to control the risk maximization. We analyze the empirical Bayes risk with respect to the box-constrained priors for discrete inputs. We show that this risk is a concave non-differentiable multivariate piecewise affine function. A projected subgradient algorithm is derived to maximize this empirical Bayes risk over the box-constrained simplex. Its convergence is established and its speed is bounded. The optimization algorithm is scalable when the number of classes is large. The robustness of our classifier is studied on diverse databases. Our classifier, jointly applied with a clustering algorithm to process mixed attributes, tends to equalize the class-conditional risks while being not too pessimistic.},
	number = {6},
	urldate = {2025-04-25},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Gilet, Cyprien and Barbosa, Susana and Fillatre, Lionel},
	month = jun,
	year = {2022},
	keywords = {Bayes methods, Bayesian robustness, discrete bayes classifier, Equalizers, histogram rule, imbalanced datasets, Medical diagnostic imaging, Minimax classifier, prior probability shift, Robustness, Support vector machines, Task analysis, Training, uncertain class proportions, Γ Γ -minimax classifier},
	pages = {2923--2937},
	file = {Snapshot:/Users/fillatre/Zotero/storage/JIZXZR6M/9302706.html:text/html;Version soumise:/Users/fillatre/Zotero/storage/CLTGX77S/Gilet et al. - 2022 - Discrete Box-Constrained Minimax Classifier for Uncertain and Imbalanced Class Proportions.pdf:application/pdf},
}

@inproceedings{guyomard_understandable_2023,
	title = {Understandable {Relu} {Neural} {Network} {For} {Signal} {Classification}},
	url = {https://ieeexplore.ieee.org/document/10095422},
	doi = {10.1109/ICASSP49357.2023.10095422},
	abstract = {ReLU neural networks suffer from a problem of explainability because they partition the input space into a lot of polyhedrons. This paper proposes a constrained neural network model that replaces polyhedrons by orthotopes: each hidden neuron processes only a single component of the input signal. When the number of hidden neurons is large, we show that our neural network is equivalent to a logistic regression whose input is a non-linear transformation of the processed signal. Hence, the training of our neural network always converges to a unique solution. Numerical simulations show that the loss of performance with respect to state-of-the-art methods is negligible even though our neural network is strongly constrained on robustness and explainability.},
	urldate = {2025-04-25},
	booktitle = {{ICASSP} 2023 - 2023 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Guyomard, Marie and Barbosa, Susana and Fillatre, Lionel},
	month = jun,
	year = {2023},
	note = {ISSN: 2379-190X},
	keywords = {General additive model, Logistic regression, Neural network, Neurons, Numerical models, Numerical simulation, Pattern classification, Robustness, Signal processing, Spline approximation, Training},
	pages = {1--5},
	file = {Snapshot:/Users/fillatre/Zotero/storage/D6UKW6NW/10095422.html:text/html},
}

@inproceedings{resmerita_classification_2021,
	title = {Classification {Error} {Approximation} of a {Compressed} {Linear} {Softmax} {Layer}},
	url = {https://ieeexplore.ieee.org/document/9616015},
	doi = {10.23919/EUSIPCO54536.2021.9616015},
	abstract = {Deep neural networks need to be compressed due to their high memory requirements and computational complexity. Previous papers have proposed numerous methods to quantize the weights with a single bit or more. However, the loss of accuracy involved in the compression is scarcely studied from a theoretical point of view. Motivated by the rate-distortion theory, we propose a new distortion measure which assesses the gap between the Bayes risk of a classifier before and after the compression. Since this distortion is not easily tractable, we derive a theoretical approximation when the last fully connected layer of a deep neural network is compressed under the assumption that the layer inputs follow a multivariate normal distribution. Numerical results show that the approximation performs well on both synthetic and real data. We also show that heuristic quantizers proposed in the literature may not be optimal.},
	urldate = {2025-04-25},
	booktitle = {2021 29th {European} {Signal} {Processing} {Conference} ({EUSIPCO})},
	author = {Resmerita, Diana and Farias, Rodrigo Cabral and Fillatre, Lionel},
	month = aug,
	year = {2021},
	note = {ISSN: 2076-1465},
	keywords = {Analytical models, Deep learning, Europe, Gaussian distribution, Memory management, Quantization (signal), Rate-distortion},
	pages = {1446--1450},
	file = {Snapshot:/Users/fillatre/Zotero/storage/YNKU2FGV/9616015.html:text/html},
}

@inproceedings{thomas_learning-based_2022,
	title = {Learning-{Based} {Scattering} {Transform} for {Explainable} {Classification}},
	url = {https://ieeexplore.ieee.org/document/9909816},
	doi = {10.23919/EUSIPCO55093.2022.9909816},
	abstract = {Vessel noise classification is generally considered as a challenging task due to its need for robustness and reliability. Thus, classification in this domain mainly relied on expert feature. Raw waveform architectures have been historically avoided, despite their performances in other domains. This paper proposes a Learning-based Scattering Transform (LST) that efficiently learns temporal dependencies within cyclostationary signals, such as vessel noises. The LST is implememented as a Convolutional Neural Network (CNN) with short filters whose structure mimics a multiscale signal decomposition. By this way, the architecture of our neural network is intrinsically explainable. Numerical simulations compare our method to an other explainable model and classic convolutional neural networks.},
	urldate = {2025-04-25},
	booktitle = {2022 30th {European} {Signal} {Processing} {Conference} ({EUSIPCO})},
	author = {Thomas, Mahiout and Lionel, Fillatre and Laurent, Deruaz-Pepin},
	month = aug,
	year = {2022},
	note = {ISSN: 2076-1465},
	keywords = {Bayes detection, CNN, Convolutional neural networks, Explainability, MIMICs, Numerical models, Numerical simulation, Robustness, Scattering, Scattering transform, Ship acoustic signal, Wavelet transforms},
	pages = {1402--1406},
	file = {Snapshot:/Users/fillatre/Zotero/storage/FM58XWQH/9909816.html:text/html},
}
