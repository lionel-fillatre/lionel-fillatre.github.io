@inproceedings{schall_optimal_2025,
 abstract = {The importance of features interactions for classification tasks between two classes is proven by the abundance of high-performance machine learning methods using them. In this paper, we take our inspiration from Bayesian Networks (BNs), a famous classification method whose main asset is the graphical representation of links between features. In the case of discrete feature, we assume that the features follow a tree-based distribution under each class. Then, we show that the optimal Bayes classifier coincides with a logistic regression whose features are one-hot encoded with a specific scheme. We show the advantages of such an approach both theoretically and numerically, especially showing that the learning step always converges toward a unique solution. Simulated experiments confirm the efficiency of the one-hot logistic regression with feature interaction encoding.},
 author = {Schall, Baptiste and Anty, Rodolphe and Fillatre, Lionel},
 booktitle = {ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
 doi = {10.1109/ICASSP49660.2025.10889704},
 keywords = {Acoustics, Bayes Classifier, Bayesian Network, Binary classification, Encoding, Light rail systems, Logistic regression, Logistic Regression, Naive Bayes methods, One-hot encoding, Random forests, Signal processing, Speech processing},
 month = {April},
 note = {ISSN: 2379-190X},
 pages = {1--5},
 title = {Optimal One-hot Logistic Regression for Tree-based Distribution Classification},
 url = {https://ieeexplore.ieee.org/document/10889704},
 urldate = {2025-04-25},
 year = {2025}
}
